[ansible_control_node]
127.0.0.1 ansible_connection="local"

[ansible_managed_nodes]
# By default use ansible as the username to ssh into managed nodes
# However, for initially bootstrapping the managed nodes use the manaully created user in the image
ayuraya ansible_user="ayuraya" ansible_ssh_private_key_file="~/.ssh/boot/id_rsa"
node1 ansible_user="node1" ansible_ssh_private_key_file="~/.ssh/boot/id_rsa"
node2 ansible_user="node2" ansible_ssh_private_key_file="~/.ssh/boot/id_rsa"

[nfs_server]
127.0.0.1 ansible_connection="local"

[nfs_clients]
ayuraya
node1
node2

[k3s_control_nodes]
ayuraya

[k3s_data_nodes]
node1
node2

[k3s_cluster:children]
k3s_control_nodes
k3s_data_nodes

[k3s_cluster:vars]
# apiserver_endpoint is virtual ip-address which will be configured on each master
k3s_cn_apiserver_endpoint='192.168.86.20'
k3s_cn_group_name='k3s_control_nodes'
# k3s_token is required  masters can talk together securely
# this token should be alpha numeric only
# currently not applicable since we only have one master so far
k3s_cn_token="sanjeevgiritoken"
# k3s_first_cn is a boolean value which is true for the first control node
k3s_first_cn="{{ ansible_hostname == hostvars[groups[k3s_cn_group_name | default('k3s_control_nodes')][0]]['ansible_hostname'] }}"

[all:vars]
ansible_user='ansible'
systemd_dir='/etc/systemd/system'
system_timezone='Etc/UTC'
ansible_username='ansible'
ansible_userhome='/home/ansible'
ansible_uid='2000'
ansible_groupname='ansible'
ansible_gid='2000'
nfs_server_ip='192.168.86.10'
nfs_export_path='/mnt/usbs/pioneer1'
